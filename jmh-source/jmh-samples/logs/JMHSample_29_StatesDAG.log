# JMH version: 1.22-SNAPSHOT
# VM version: JDK 1.8.0_112, Java HotSpot(TM) 64-Bit Server VM, 25.112-b15
# VM invoker: /home/hadoop/jdk1.8.0_112/jre/bin/java
# VM options: <none>
# Warmup: 5 iterations, 1 s each
# Measurement: 5 iterations, 1 s each
# Timeout: 10 min per iteration
# Threads: 1 thread, will synchronize iterations
# Benchmark mode: Average time, time/op
# Benchmark: org.openjdk.jmh.samples.JMHSample_29_StatesDAG.test

# Run progress: 0.00% complete, ETA 00:00:10
# Fork: 1 of 1
# Warmup Iteration   1: 6.167 ns/op
# Warmup Iteration   2: 5.504 ns/op
# Warmup Iteration   3: 3.849 ns/op
# Warmup Iteration   4: 3.944 ns/op
# Warmup Iteration   5: 3.873 ns/op
Iteration   1: 3.903 ns/op
Iteration   2: 4.015 ns/op
Iteration   3: 3.845 ns/op
Iteration   4: 3.724 ns/op
Iteration   5: 3.724 ns/op


Result "org.openjdk.jmh.samples.JMHSample_29_StatesDAG.test":
  3.842 ±(99.9%) 0.478 ns/op [Average]
  (min, avg, max) = (3.724, 3.842, 4.015), stdev = 0.124
  CI (99.9%): [3.364, 4.320] (assumes normal distribution)


# Run complete. Total time: 00:00:10

REMEMBER: The numbers below are just data. To gain reusable insights, you need to follow up on
why the numbers are the way they are. Use profilers (see -prof, -lprof), design factorial
experiments, perform baseline and negative tests that provide experimental control, make sure
the benchmarking environment is safe on JVM/OS/HW level, ask for reviews from the domain experts.
Do not assume the numbers tell you what you want them to tell.

Benchmark                    Mode  Cnt  Score   Error  Units
JMHSample_29_StatesDAG.test  avgt    5  3.842 ± 0.478  ns/op
